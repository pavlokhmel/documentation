<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Storage areas on HPC clusters &mdash; Sigma2 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/nris.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/nris.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://siteimproveanalytics.com/js/siteanalyze_6036825.js"></script>
        <script src="../_static/design-tabs.js?v=36754332"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Storage quota" href="quota.html" />
    <link rel="prev" title="Data handling and storage policy" href="sharing_files.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Sigma2/NRIS documentation
              <img src="../_static/NRIS Logo.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Policies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code-of-conduct.html">Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/support_line.html">Getting help</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/extended_support.html">Extended support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/how_to_write_good_support_requests.html">Writing good support requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/user_communities.html">User communities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/qa-sessions.html">Open Question &amp; Answer Sessions for All Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/lost_forgotten_password.html">Lost, expiring or changing passwords</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/project_leader_support.html">Project leader support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../training/events.html">Training events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/notes_qa.html">Questions, Answers and Feedbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/videos.html">Training Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/material.html">Training materials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/opslog.html">Using the status system (opslog)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/applying_account.html">How do I get an account?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/applying_resources.html">Applying for computing and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/editing_files.html">Editing files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_development/guides/vs_code/connect_to_server.html">Connecting to a system with Visual Studio Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/ssh.html">SSH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/remote-desktop.html">Remote Desktop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/R.html">First R calculation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nird_archive/user-guide.html">Research Data Archive (NIRD RDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nird_toolkit/overview.html">NIRD Toolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../services/easydmp-user-documentation.html">EasyDMP User Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_help/course_resources.html">CRaaS - Course Resources as a Service</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">HPC usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../hpc_machines/migration2metacenter.html">Migration to an NRIS HPC machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computing/responsible-use.html">Using shared resources responsibly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jobs/overview.html">Running jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computing/tuning-applications.html">Tuning applications</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code development and tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code_development/overview.html">Code development and tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../software/modulescheme.html">Software module scheme</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/installed_software.html">Installed software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/userinstallsw.html">Installing software as user</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/appguides.html">Application guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/licenses.html">Licence and access policies</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Files, storage and backup</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="nird_lmd.html">NIRD</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Storage areas on HPC clusters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#home-directory">Home directory</a></li>
<li class="toctree-l2"><a class="reference internal" href="#job-scratch-area">Job scratch area</a></li>
<li class="toctree-l2"><a class="reference internal" href="#job-scratch-area-on-local-disk">Job scratch area on local disk</a></li>
<li class="toctree-l2"><a class="reference internal" href="#user-work-area">User work area</a></li>
<li class="toctree-l2"><a class="reference internal" href="#project-area">Project area</a></li>
<li class="toctree-l2"><a class="reference internal" href="#shared-project-area">Shared project area</a></li>
<li class="toctree-l2"><a class="reference internal" href="#decommissioning">Decommissioning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quota.html">Storage quota</a></li>
<li class="toctree-l1"><a class="reference internal" href="backup.html">Backup on Betzy, Fram, Saga, and NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="file_transfer.html">File transfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="sharing_files.html">Data handling and storage policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Optimizing storage performance</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Sigma2/NRIS documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Storage areas on HPC clusters</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/UNINETTSigma2/documentation/blob/main/files_storage/clusters.md" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="storage-areas-on-hpc-clusters">
<span id="storage-areas"></span><h1><a class="toc-backref" href="#id5" role="doc-backlink">Storage areas on HPC clusters</a><a class="headerlink" href="#storage-areas-on-hpc-clusters" title="Link to this heading"></a></h1>
<p>Projects and users receive different areas to store files and other
data. Some areas are used for temporary files during job execution
while others are for storing project data.</p>
<nav class="contents" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#storage-areas-on-hpc-clusters" id="id5">Storage areas on HPC clusters</a></p>
<ul>
<li><p><a class="reference internal" href="#overview" id="id6">Overview</a></p></li>
<li><p><a class="reference internal" href="#home-directory" id="id7">Home directory</a></p></li>
<li><p><a class="reference internal" href="#job-scratch-area" id="id8">Job scratch area</a></p></li>
<li><p><a class="reference internal" href="#job-scratch-area-on-local-disk" id="id9">Job scratch area on local disk</a></p></li>
<li><p><a class="reference internal" href="#user-work-area" id="id10">User work area</a></p></li>
<li><p><a class="reference internal" href="#project-area" id="id11">Project area</a></p></li>
<li><p><a class="reference internal" href="#shared-project-area" id="id12">Shared project area</a></p></li>
<li><p><a class="reference internal" href="#decommissioning" id="id13">Decommissioning</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="overview">
<span id="clusters-overview"></span><h2><a class="toc-backref" href="#id6" role="doc-backlink">Overview</a><a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>The following table summarizes the different storage options for <strong>Betzy, Fram, and Saga</strong>.
Below the table we give recommendations and discuss pros and cons for the various storage areas.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Directory</p></th>
<th class="head text-left"><p>Purpose</p></th>
<th class="head text-left"><p><a class="reference internal" href="quota.html#storage-quota"><span class="std std-ref">Default Quota</span></a></p></th>
<th class="head text-center"><p><a class="reference internal" href="backup.html#storage-backup"><span class="std std-ref">Backup</span></a></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/cluster/home/$USER</span></code> (<code class="docutils literal notranslate"><span class="pre">$HOME</span></code>)</p></td>
<td class="text-left"><p>User data</p></td>
<td class="text-left"><p>20 GiB / 100 K files</p></td>
<td class="text-center"><p>Only if quota enforced</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/cluster/work/jobs/$SLURM_JOB_ID</span></code> (<code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code>)</p></td>
<td class="text-left"><p>Per-job data</p></td>
<td class="text-left"><p>N/A</p></td>
<td class="text-center"><p>No</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>(Fram/Saga) <code class="docutils literal notranslate"><span class="pre">/localscratch/$SLURM_JOB_ID</span></code> (<code class="docutils literal notranslate"><span class="pre">$LOCALSCRATCH</span></code>)</p></td>
<td class="text-left"><p>Per-job data</p></td>
<td class="text-left"><p><a class="reference internal" href="#job-scratch-area-on-local-disk"><span class="std std-ref">Individual</span></a></p></td>
<td class="text-center"><p>No</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/cluster/work/users/$USER</span></code> (<code class="docutils literal notranslate"><span class="pre">$USERWORK</span></code>)</p></td>
<td class="text-left"><p>Staging and job data</p></td>
<td class="text-left"><p>N/A</p></td>
<td class="text-center"><p>No</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/cluster/projects/&lt;project_name&gt;</span></code></p></td>
<td class="text-left"><p>Project data</p></td>
<td class="text-left"><p><a class="reference internal" href="#project-area"><span class="std std-ref">1 TiB / 1 M files</span></a></p></td>
<td class="text-center"><p>Yes</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">/cluster/shared/&lt;folder_name&gt;</span></code></p></td>
<td class="text-left"><p>Shared data</p></td>
<td class="text-left"><p><a class="reference internal" href="#shared-project-area"><span class="std std-ref">Individual</span></a></p></td>
<td class="text-center"><p>No</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p><strong>User areas and project areas are private</strong>: Data handling and storage policy is documented <a class="reference internal" href="sharing_files.html"><span class="std std-doc">here</span></a>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">$LOCALSCRATCH</span></code> area is only implemented on Fram and Saga</strong>.</p></li>
<li><p>In addition to the areas in the tables above, <strong>both clusters mount the
NIRD project areas</strong> as <code class="docutils literal notranslate"><span class="pre">/nird/projects/nird/NSxxxxK</span></code> on the login nodes
(but not on the compute nodes).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">/cluster</span></code> file system is a high-performance parallel file
system.  On Fram, it is a <a class="reference external" href="https://www.lustre.org/">Lustre</a> system with
a total storage space of 2.3 PB, and on Saga it is a
<a class="reference external" href="https://www.beegfs.io/">BeeGFS</a> system with a total storage space of
6.5 PB.
For performance optimizations, consult <a class="reference internal" href="performance.html#storage-performance"><span class="std std-ref">Optimizing storage performance</span></a>.</p></li>
</ul>
</section>
<section id="home-directory">
<span id="clusters-homedirectory"></span><h2><a class="toc-backref" href="#id7" role="doc-backlink">Home directory</a><a class="headerlink" href="#home-directory" title="Link to this heading"></a></h2>
<p>The home directory is <code class="docutils literal notranslate"><span class="pre">/cluster/home/$USER</span></code>. The location is stored
in the environment variable <code class="docutils literal notranslate"><span class="pre">$HOME</span></code>.  <a class="reference internal" href="quota.html#storage-quota"><span class="std std-ref">Storage quota</span></a> is enabled on home
directories which is by default 20 GiB and 100 000 files, so it
is not advisable to run jobs in <code class="docutils literal notranslate"><span class="pre">$HOME</span></code>. However, it is perfectly
fine to store <code class="docutils literal notranslate"><span class="pre">stderr</span></code> and <code class="docutils literal notranslate"><span class="pre">stdout</span></code> logs from your batch jobs in
<code class="docutils literal notranslate"><span class="pre">$HOME</span></code> so they are available for reviewing in case of issues with it.</p>
<p>The home directory should be used for storing tools, scripts, application
sources or other relevant data which must have a backup.</p>
<p>The home directory is only accessible for the user. Files that should be
accessible by other uses in a project must be placed in the project
area.</p>
<p><a class="reference internal" href="backup.html#storage-backup"><span class="std std-ref">Backed up</span></a>
with daily snapshots <strong>only if <a class="reference internal" href="quota.html#storage-quota"><span class="std std-ref">Storage quota</span></a> is enforced</strong> for the last 7
days and weekly snapshots for the last 6 weeks.</p>
</section>
<section id="job-scratch-area">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Job scratch area</a><a class="headerlink" href="#job-scratch-area" title="Link to this heading"></a></h2>
<p>Each job gets an area <code class="docutils literal notranslate"><span class="pre">/cluster/work/jobs/$SLURM_JOB_ID</span></code> that is
automatically created for the job, and automatically deleted when the
job finishes.  The location is stored in the environment variable
<code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> available in the job.  <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> is only accessible by the
user running the job.</p>
<p>On Fram and Saga there are two scratch areas (see also below).</p>
<p>The area is meant as a temporary scratch area during job
execution.
<strong>This area is not backed up</strong> (<a class="reference internal" href="backup.html"><span class="std std-doc">documentation about backup</span></a>).</p>
<p>There are special commands (<code class="docutils literal notranslate"><span class="pre">savefile</span></code> and <code class="docutils literal notranslate"><span class="pre">cleanup</span></code>) one can use in
the job script to ensure that files are copied back to the submit
directory <code class="docutils literal notranslate"><span class="pre">$SLURM_SUBMIT_DIR</span></code> (where <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> was run).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Pros of running jobs in the job scratch area</strong></p>
<ul class="simple">
<li><p>There is less risk of interference from other jobs because every job ID has
its own scratch directory.</p></li>
<li><p>Because the scratch directory is removed when the job finishes, the scripts
do not need to clean up temporary files.</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><strong>Cons of running jobs in the job scratch area</strong></p>
<ul class="simple">
<li><p>Since the area is removed automatically, it can be hard to debug
jobs that fail.</p></li>
<li><p>One must use the special commands to copy files back in case the job
script crashes before it has finished.</p></li>
<li><p>If the main node of a job crashes (i.e., not the job script, but the
node itself), the special commands might not be run, so files might
be lost.</p></li>
</ul>
</div>
</section>
<section id="job-scratch-area-on-local-disk">
<span id="id1"></span><h2><a class="toc-backref" href="#id9" role="doc-backlink">Job scratch area on local disk</a><a class="headerlink" href="#job-scratch-area-on-local-disk" title="Link to this heading"></a></h2>
<p><strong>This only exists on Fram and Saga</strong>.</p>
<p>A job on <strong>Fram/Saga</strong> can request a scratch area on local disk on the node
it is running on.  This is done by specifying
<code class="docutils literal notranslate"><span class="pre">--gres=localscratch:&lt;size&gt;</span></code>, where <em><size></em> is the size of the requested
area, for instance <code class="docutils literal notranslate"><span class="pre">--gres=localscratch:20G</span></code> for 20 GiB.</p>
<p>Compute nodes on Fram have 198GiB disk that can be handed out to local scratch areas.
On Saga most nodes have 300 GiB; a few of the
bigmem nodes have 7 TiB and the GPU nodes have 8 TiB.  If a job tries
to use more space on the area than it requested, it will get a “disk
quota exceeded” or “no space left on device” error (the exact message
depends on the program doing the writing).
Please do not ask for more than what you actually need, other users might share
the local scratch space with you (Saga only).</p>
<p>Jobs that request a local scratch area, get an area <code class="docutils literal notranslate"><span class="pre">/localscratch/$SLURM_JOB_ID</span></code>
that is automatically created for the job, and automatically deleted
when the job finishes.  The location is stored in the environment
variable <code class="docutils literal notranslate"><span class="pre">$LOCALSCRATCH</span></code> available in the job.  <code class="docutils literal notranslate"><span class="pre">$LOCALSCRATCH</span></code> is
only accessible by the user running the job.</p>
<p>Note that since this area is on <em>local disk</em> on the compute node, it
is probably not useful for jobs running on more than one node (the job
would get one independent area on each node).</p>
<p>The area is meant to be used as a temporary scratch area during job
execution by jobs who do a lot of disk IO operations (either metadata
operations or read/write operations).  Using it for such jobs will
speed up the jobs, and reduce the load on the <code class="docutils literal notranslate"><span class="pre">/cluster</span></code> file system.</p>
<p><strong>This area is not backed up</strong> (<a class="reference internal" href="backup.html"><span class="std std-doc">documentation about backup</span></a>).</p>
<p>Currently, there are <em>no</em> special commands to ensure that files are
copied back automatically, so one has to do that with <code class="docutils literal notranslate"><span class="pre">cp</span></code> commands or
similar in the job script.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Pros of running jobs in the local disk job scratch area</strong></p>
<ul class="simple">
<li><p>Input/output operations are faster than on the <code class="docutils literal notranslate"><span class="pre">/cluster</span></code> file system.</p></li>
<li><p>Great if you need to write/read a large number of files.</p></li>
<li><p>It reduces the load on the <code class="docutils literal notranslate"><span class="pre">/cluster</span></code> file system.</p></li>
<li><p>There is less risk of interference from other jobs because every job ID has
its own scratch directory.</p></li>
<li><p>Because the scratch directory is removed when the job finishes, the scripts
do not need to clean up temporary files.</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><strong>Cons of running jobs in the local disk job scratch area</strong></p>
<ul class="simple">
<li><p>Since the area is removed automatically, it can be hard to debug
jobs that fail.</p></li>
<li><p>Not suitable for files larger than 198-300 GB.</p></li>
<li><p>One must make sure to use <code class="docutils literal notranslate"><span class="pre">cp</span></code> commands or similar in the job
script to copy files back.</p></li>
<li><p>If the main node of a job crashes (i.e., not the job script, but the
node itself), files might be lost.</p></li>
</ul>
</div>
</section>
<section id="user-work-area">
<span id="id2"></span><h2><a class="toc-backref" href="#id10" role="doc-backlink">User work area</a><a class="headerlink" href="#user-work-area" title="Link to this heading"></a></h2>
<p>Each user has an area <code class="docutils literal notranslate"><span class="pre">/cluster/work/users/$USER</span></code>.  The location is
stored in the environment variable <code class="docutils literal notranslate"><span class="pre">$USERWORK</span></code>.
<strong>This area is not backed up</strong> (<a class="reference internal" href="backup.html"><span class="std std-doc">documentation about backup</span></a>).
By default, <code class="docutils literal notranslate"><span class="pre">$USERWORK</span></code> is a private area and only accessible by
the user owning the area. However, it is possible to grant other
users access here, for e.g., debugging purposes. Note that write
access to your <code class="docutils literal notranslate"><span class="pre">$USERWORK</span></code> can not be granted to others.</p>
<p>To allow others to read your work area, you may use the command:
<code class="docutils literal notranslate"><span class="pre">chmod</span> <span class="pre">o+rx</span> <span class="pre">$USERWORK</span></code></p>
<p>Note that by doing so you will allow everyone on the machine to
access your user work directory. If you want to share the results
in <code class="docutils literal notranslate"><span class="pre">$USERWORK</span></code> with other people in the project, the best way is to
move them to the project area.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">$USERWORK</span></code> directory is meant for files that are used by one
or more jobs. All result files must be moved out from this area
after the jobs finish, otherwise they will be automatically deleted
after a while (see notes below). We highly encourage users to keep
this area tidy, since both high disk usage and automatic deletion
process takes away disk performance. The best solution is to clean up
any unnecessary data after each job.</p>
<p>File deletion depends on the newest of the <em>creation-</em>, <em>modification-</em> and
<em>access</em> time and the total usage of the file system. The oldest files will
be deleted first and a weekly scan removes files older than 42 days.</p>
<p>When file system usage reaches 70%, files older than 21 days are subject to
automatic deletion. If usage is over 90%, files older then 17 days are subject to
automatic deletion.</p>
<p>It is <strong>not</strong> allowed to try to circumvent the automatic deletion by
for instance running scripts that touch all files.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Pros of running jobs in the user work area</strong></p>
<ul class="simple">
<li><p>Since job files are not removed automatically directly when a job
finishes, it is easier to debug failing jobs.</p></li>
<li><p>There is no need to use special commands to copy files back in case
the job script or node crashes before the job has finished.</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><strong>Cons of running jobs in the user work area</strong></p>
<ul class="simple">
<li><p>There is a risk of interference from other jobs unless one makes
sure to run each job in a separate sub directory inside <code class="docutils literal notranslate"><span class="pre">$USERWORK</span></code>.</p></li>
<li><p>Because job files are not removed when the job finishes, one has to
remember to clean up temporary files afterwards.</p></li>
<li><p>One has to remember to move result files to the project area if one
wants to keep them.  Otherwise they will eventually be deleted by
the automatic file deletion.</p></li>
</ul>
</div>
</section>
<section id="project-area">
<span id="id3"></span><h2><a class="toc-backref" href="#id11" role="doc-backlink">Project area</a><a class="headerlink" href="#project-area" title="Link to this heading"></a></h2>
<p>All HPC projects have a dedicated local space to share data between project
members, located at <code class="docutils literal notranslate"><span class="pre">/cluster/projects/&lt;project_name&gt;</span></code>.</p>
<p>The project area is controlled with <a class="reference internal" href="quota.html#storage-quota"><span class="std std-ref">Storage quota</span></a> and the default project quota for
HPC projects is 1 TB, but projects can apply for more during the
application process with a maximum quota of 10 TB.</p>
<p>Also after the project has been created, project members can request to increase
the quota to up to 10 TB by motivating why this is needed. Such requests should be submitted by the project leader via e-mail to <a class="reference external" href="mailto:contact&#37;&#52;&#48;sigma2&#46;no?subject=Storage%20Quota%20Request%20project%20X&amp;amp;body=1&#46;%20How%20large%20are%20the%20input%20files%3F%20(Approximate%20or%20exact%20numbers%20are%20fine&#46;)%0A%0A2&#46;%20How%20many%20such%20input%20files%20will%20be%20used%20in%20a%20single%20job%3F%0A%0A3&#46;%20At%20what%20rate%20do%20you%20intend%20to%20process%20your%20data%3F%20(Approximate%20GB%20per%20week%20or%20equivalent&#46;)%0A%0A4&#46;%20What%20size%20is%20your%20output%20files%20and%20will%20you%20use%20this%20data%20as%20input%20in%20further%20analysis%3F%0A%0A5&#46;%20Please%20explain%20why%20you%20cannot%20benefit%20from%20the%20%2Fcluster%2Fwork%20area%0A%0A6&#46;%20Based%20on%20your%20answers%20above%2C%20how%20much%20storage%20quota%20do%20you%20think%20you%20need%3F">contact<span>&#64;</span>sigma2<span>&#46;</span>no</a>
. Note that only files that are relevant for further computation jobs should be kept on the HPC machine. HPC is not intended for long term storage. In your request, please include answers to the following questions:</p>
<ol class="arabic simple">
<li><p>How large are the input files? (Approximate or exact numbers are fine.)</p></li>
<li><p>How many such input files will be used in a single job?</p></li>
<li><p>At what rate do you intend to process your data? (Approximate GB per week or equivalent.)</p></li>
<li><p>What size is your output files and will you use this data as input in further analysis?</p></li>
<li><p>Please explain why you cannot benefit from the /cluster/work area</p></li>
<li><p>Based on your answers above, how much storage quota do you think you need?</p></li>
</ol>
<p>Requests for more than 10 TB require an application for a separate <a class="reference internal" href="nird_lmd.html#nird"><span class="std std-ref">NIRD</span></a> project area.</p>
<p>Note that unused quota can also be withdrawn for technical reasons (too little
space) or organisational reasons (less needs/less usage/less members of
group/less compute hrs).</p>
<p>Daily backup is taken to NIRD (<a class="reference internal" href="backup.html"><span class="std std-doc">documentation about backup</span></a>).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Pros of running jobs in the project area</strong></p>
<ul class="simple">
<li><p>Since job files are not removed automatically directly when a job
finishes, it is easier to debug failing jobs.</p></li>
<li><p>There is no need to use special commands to copy files back in case
the job script or node crashes before the job has finished.</p></li>
<li><p>There is no need to move result files to save them permanently or
give the rest of the project access to them.</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><strong>Cons of running jobs in the project area</strong></p>
<ul class="simple">
<li><p>There is a risk of interference from other jobs unless one makes
sure to run each job in a separate sub directory inside the project
area.</p></li>
<li><p>Because job files are not removed when the job finishes, one has to
remember to clean up temporary files afterwards, otherwise they can
fill up the quota.</p></li>
<li><p>There is a risk of using all of the disk quota if one runs many jobs
and/or jobs needing a lot of storage at the same time.</p></li>
</ul>
</div>
</section>
<section id="shared-project-area">
<span id="id4"></span><h2><a class="toc-backref" href="#id12" role="doc-backlink">Shared project area</a><a class="headerlink" href="#shared-project-area" title="Link to this heading"></a></h2>
<p>In special cases there might be a need for sharing data between projects for
collaboration and possibly preventing data duplication.</p>
<p>If such a need is justified, a meta-group and it’s according directory
in <code class="docutils literal notranslate"><span class="pre">/cluster/shared</span></code> is created.  The area gets a disk quota based on
the needs of the data.  The permissions of the areas vary.  In some
cases all but a few users in the meta-group only have read-only access
to the area.  In other cases, all users on the cluster have read-only
access.</p>
</section>
<section id="decommissioning">
<h2><a class="toc-backref" href="#id13" role="doc-backlink">Decommissioning</a><a class="headerlink" href="#decommissioning" title="Link to this heading"></a></h2>
<p>Starting at the 2020.1 resource allocation period, storage decommissioning
procedures have been established for the HPC storages. This to ensure
predictable astorage for users and projects, and the provisioning more
sustainable to Sigma2.
For more details, please visit the
<a class="reference external" href="https://www.sigma2.no/data-decommissioning-policies">data decommissioning policies</a>
page.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sharing_files.html" class="btn btn-neutral float-left" title="Data handling and storage policy" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quota.html" class="btn btn-neutral float-right" title="Storage quota" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Sigma2/NRIS. Text shared under CC-BY 4.0 license.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Integrate opslog banner -->
<span class="sp-status"></span>
<script>
  window.statuspalWidget = {
    subdomain: 'sigma2-nris',
    host: 'https://statuspal.eu',
    badge: {
      enabled: false,
      selector: '.sp-status', 
    },
    banner: {
      enabled: true,
      position: 'top-right',
    }
  }
</script>
<script src="https://statuspal.io/js/widget.js"></script>


</body>
</html>